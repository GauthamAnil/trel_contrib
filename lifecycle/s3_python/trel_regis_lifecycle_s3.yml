name: lifecycle.<repository_name>

execution.profile: python # or emr_pyspark or dataproc_pyspark

execution.source_code.main:
  class: github
  branch: main
  path: git@github.com:GauthamAnil/trel_contrib.git
execution.main_executable: _code/lifecycle/s3_python/s3.py

repository_map:
  # The actions may be stored in a different repository more compatible with the compute technology. In this case,
  # we can choose the same repository as this is s3.
  - lifecycle.actions: <repository_name> 
  
execution.output_generator:
  class: default
  outputs:
    - dataset_class: lifecycle.actions.complete

resource.name: emr_spark
resource.memory_level: normal
resource.num_cores: 1
resource.args:
  region: <repository region (recommended)>
  spot: true

scheduler:
  class: single_instance
  instance_prefix: <repository_name>
  depends_on: [ lifecycle.actions ]
  labels: [ lifecycle ]
  instance_ts_precisions: [ H ]
  cron_constraint: "0 * * * *"
  schedule_ts_min: "2019-01-01 00:00:00"
 